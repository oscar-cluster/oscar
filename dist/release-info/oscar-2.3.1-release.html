<html>
<head>
<title>Press release for OSCAR 2.3.1</title>
</head>
<body>


<p>
OAK RIDGE, Tenn., October 6, 2003 -- The OSCAR working group  has  release
version 2.3.1 of the Open Source  Cluster  Application	Resources  (OSCAR)
toolkit.

<p>
The OSCAR toolkit is used to build, configure and  manage  clusters.   Its
primary objective is to make use of  "best	practices"	for  Cluster  High
Performance Computing (HPC).  OSCAR enables a user to setup  and  maintain
a cluster with the same software typically found on  HPC  Clusters,  while
greatly reducing the complexity  of  the  installation	and  configuration
process.

<p>
This release has fully tested support for Red Hat 8.0,	9.0  and  Mandrake
9.0.  The underlying installation tool, System Installation  Suite	(SIS),
was updated to include a new release of  SystemImager.	 The  SystemImager
tool now  provides	multicast  installation  capabilities.	 The  Cluster,
Command and Control (C3)  tool	have  also	been  updated  to  the	latest
scalability  release  4.0.

<p>
In addition to these build	system	enhancements,  a  new  graphical  user
interface was added to the OSCAR Package Downloader (OPD).	This  addition
to the OSCAR wizard enables a user to download	additional	packages  from
on-line repositories prior to the cluster install.	Also, portions of  the
wizard's appearance have been improved by using the Qt windowing  toolkit.

<p>
The OSCAR packaging API has been  enhanced	for  improved  expressiveness.
Package authors can more easily convey what distribution and  architecture
their package supports.  

<p>
This release includes the new LAM/MPI 7.0.	There  are	also  several  new
OPD-able packages available, including: Myrinet, PVFS, and Clumon.	 These
packages can be obtained at the start of the install now via the GUI based
OPD and  installed	along  with  the  directly	included  packages.   This
release

<p>
This release support IA32 systems.	Those seeking IA64 support should  use
version 2.2.1 of OSCAR for now.  These releases,  as  well	as	additional
information are available at the OSCAR project page:

   <center>
     <a href="http://sourceforge.net/projects/oscar/">http://sourceforge.net/projects/oscar/</a>
   </center>


<br>
<br>

<p>
The OSCAR working group is a consortium of industry, academic and research
participants.  Primary contributors are  Bald  Guy	Software,  Dell,  IBM,
Intel,	 Indiana   University	(IU),	Intel,	 MSC.Software,	  National
Computational Science Applications (NCSA), Oak Ridge  National	Laboratory
(ORNL) and Sherbrooke University.  OSCAR  is  the  product	of	the  OSCAR
working group of the Open  Cluster	Group  (OCG).	OCG  is  dedicated	to
making	cluster  computing	practical.	 These	groups	are  open  to  all
interested   in participating.
<p>
Related resources:
<ul>
        <li>OSCAR Working Group Homepage
        <br><a href="http://www.OpenClusterGroup.org/OSCAR/">http://www.OpenClusterGroup.org/OSCAR</a>

        <br>
        <br>
        <li>OSCAR Project Homepage
        <br><a href="http://sourceforge.net/projects/oscar/">http://sourceforge.net/projects/oscar</a>

        <br>
        <br>
        <li>Open Cluster Group Homepage
            <br><a href="http://www.OpenClusterGroup.org/">http://www.OpenClusterGroup.org</a>

        <br>
        <br>
        <li>OSCAR Mailing Lists
            <br>&nbsp;&nbsp;User Questions: &lt;<a href="mailto:oscar-users@lists.sourceforge.net">oscar-users@lists.sourceforge.net</a>&gt;
            <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Development: &lt;<a href="mailto:oscar-devel@lists.sourcefore.net">oscar-devel@lists.sourcefore.net</a>&gt;


        <br>
        <br>
        <li>Thin-OSCAR (diskless) Working Group Homepage 
        <br><a href="http://www.OpenClusterGroup.org/Thin-OSCAR">http://www.OpenClusterGroup.org/Thin-OSCAR</a>

        <br>
        <br>
        <li>HA-OSCAR (high-availability) Working Group Homepage
        <br><a href="http://www.OpenClusterGroup.org/HA-OSCAR">http://www.OpenClusterGroup.org/HA-OSCAR</a>
</ul>

<br>
<p>
ORNL is a Department of Energy	multi-program  research  facility  managed
by UT-Battelle.


</body>
</html>
