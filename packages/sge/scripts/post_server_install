#!/usr/bin/perl

# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA

# This script reads the Configurator result and sets up the configuration
# files, configures and starts up qmaster and scheduler on the OSCAR head node

# (C)opyright Bernard Li <bli@bcgsc.ca>, Babu Sundaram <babu@cs.uh.edu>

use Carp;
use File::Copy;
use XML::Simple;

use lib "$ENV{OSCAR_HOME}/lib";
use OSCAR::Database;
use OSCAR::Opkg;

# Manually setting SGE_ROOT
$ENV{SGE_ROOT} = "/opt/sge";

# Get fullpath of qconf binary.  The 'tail' command is necessary because 'bash -l' might trigger
# SSH keys generation and thus we just grab the last line
my $qconf = `bash -l -c 'which qconf' | tail -n 1`;
chomp($qconf);

# default settings if user does not configure the package
my $fullserver = "true";        # Indicates if the OSCAR server with qmaster is an exec host too
my $cellname = "default";       # Should suffice for a single installation of SGE
my $gidrange = "20000-20100";   # Allowing for upto 100 concurrently executing jobs
my $spooltype = "classic";      # Other option would be to use berkeleydb

my $admin_user = "sge";

# Obtain any custom configure values from the user
my $xml_data = "$ENV{OSCAR_PACKAGE_HOME}/.configurator.values";

my $qmasterBuffer = "";

my $hostname = `hostname`;
my $domainname = `domainname`;
chomp($hostname);
chomp($domainname);

# If user has configured the package, use the custom values, otherwise use the default
if (-e $xml_data) {
    my $ref = XMLin($xml_data);
    $fullserver = $ref->{fullserver};
    $cellname = $ref->{cellname};
    $gidrange = $ref->{gidrange};
    $spooltype = $ref->{spooltype};
}

# Set the location for the config file with default settings 
# that will guide the auto-install of qmaster and execd
my $templateFile = "$ENV{SGE_ROOT}/util/install_modules/oscar_cluster.conf";
my $qmaster_conf = "$ENV{SGE_ROOT}/myInstall.conf";
copy($templateFile, $qmaster_conf) or croak("Error during copying install template file");

# need to modify qmaster config file that drives the automated master installation
open(CONF, $qmaster_conf) or croak("Error: unable to open ($qmaster_conf)\n");

while ($line = <CONF>) {
    $qmasterBuffer = $qmasterBuffer.$line;
}

close(CONF, $qmaster_conf);

$qmaster_conf = ">".$qmaster_conf;

$qmasterBuffer =~ s/ADMIN_USER=".*"/ADMIN_USER="$admin_user"/;
$qmasterBuffer =~ s/CELL_NAME=".*"/CELL_NAME="$cellname"/;
$qmasterBuffer =~ s/GID_RANGE=".*"/GID_RANGE="$gidrange"/;
$qmasterBuffer =~ s/SPOOLING_METHOD=".*"/SPOOLING_METHOD="$spooltype"/;
$qmasterBuffer =~ s/DEFAULT_DOMAIN=".*"/DEFAULT_DOMAIN="$domainname"/;
$qmasterBuffer =~ s/QMASTER_SPOOL_DIR=".*"/QMASTER_SPOOL_DIR="$ENV{SGE_ROOT}\/$cellname\/spool\/qmaster"/;
$qmasterBuffer =~ s/EXECD_SPOOL_DIR=".*"/EXECD_SPOOL_DIR="$ENV{SGE_ROOT}\/$cellname\/spool"/;
$qmasterBuffer =~ s/DB_SPOOLING_DIR=".*"/DB_SPOOLING_DIR="$ENV{SGE_ROOT}\/$cellname\/spooldb"/;
$qmasterBuffer =~ s/EXECD_SPOOL_DIR_LOCAL=".*"/EXECD_SPOOL_DIR_LOCAL="$ENV{SGE_ROOT}\/$cellname\/spool"/;

open(CONF, $qmaster_conf) or croak("Error: unable to open ($qmaster_conf)\n");
    
print CONF $qmasterBuffer;    
    
close(CONF);

opkg_print("SGE configuration options are set, proceeding with installation...\n");

# Setup the qmaster and optionally, the execd (if so chosen by the user)
# Note: In this version, we completely eliminate the option of master 
# being an exec node no matter what the user specifies in the configurator, 
# only qmaster is installed on the OSCAR cluster head node

system("cd $ENV{SGE_ROOT} && ./inst_sge -m -auto ./myInstall.conf"); 

if ($? == -1) {
        # Something seriously wrong; qmaster installation failed
	croak("Program failed: While doing ./inst_sge -x on OSCAR head");
}
elsif($? == 0){
	# FIXME: Seems that inst_sge returns 0 even if it failed due to
	# hostname resolving to 127.0.0.1
	# Everything OK; qmaster installation success
	printf "inst_sge system function SUCCESS\n";
}
elsif ($? & 127) {
	printf "child died with signal %d, %s coredump\n",
	    ($? & 127),  ($? & 128) ? 'with' : 'without';
}
else {
	# No problem here; Mostly, a rerun of inst_sge (i.e., OSCAR's post_server_install)
	printf "Looks like inst_sge is getting repeated (return = %d) : No harm done, SUCCESS\n", $? >> 8;
}

# For now, I am avoiding from making the head node as an exec host
# system("/opt/sge/inst_sge -x");
# wait();

# Also, we make the head node as an admin host and a submit host as well
# This will make a clean separation of activities that can be done on master
# and exec hosts. That is, Master = admin + submit and all others are exec

# Need to open a new shell to be able to locate the qconf binary
system("$qconf -as $hostname") == 0 or croak("Error: Problem with adding OSCAR head as sge admin host");

# The following cannot happen since we decided not make headnode as exec
# But, we can uncomment this when we allow headnode as exec
#system("qconf -ae $hostname");

$cluster_conf = "$ENV{SGE_ROOT}/$cellname/common/configuration";
$buffer = "";

# update Cluster Configuration to use ssh for rlogin and rsh
open(CONF, $cluster_conf) or croak("Error: unable to open ($cluster_conf)\n");

while ($line = <CONF>) {
    $buffer = $buffer.$line;
}

close(CONF, $cluster_conf);

opkg_print("Updating $cluster_conf to use ssh for rsh/rlogin commands.\n");

$cluster_conf = ">".$cluster_conf;

$buffer =~ s|/usr/sbin/in.rlogind|/usr/sbin/sshd -i\nrsh_daemon\t\t  /usr/sbin/sshd -i\nrlogin_command\t\t  /usr/bin/ssh -x\nrsh_command\t\t  /usr/bin/ssh -x|;

open(CONF, $cluster_conf) or croak("Error: unable to open ($cluster_conf)\n");
print CONF $buffer;
close(CONF);

# Make sure that by default, SGE error and output files are stored in the current working directory where the job is submitted from
my $sge_request = "$ENV{SGE_ROOT}/$cellname/common/sge_request";

if (! (`grep -e '-cwd' $sge_request`) ) {        
	system("echo -cwd >> $sge_request") == 0 or croak("Failed to add -cwd to $sge_request");
}

# Set up tickets for share tree policy
my $ssconf = "/tmp/ssconf";
my $st_tickets = "10000";
$line = "";
$buffer = "";

system("$qconf -ssconf > $ssconf") == 0 or croak("Failed to execute qconf -ssconf");

open(SSCONF, $ssconf) or croak("Cannot open file $ssconf");
while ($line = <SSCONF>) {
        if ($line =~ /weight_tickets_share/) {
                $line = "weight_tickets_share              $st_tickets\n";
        }
        $buffer = $buffer.$line;
}
close(SSCONF);

open(SSCONF, ">".$ssconf) or croak("Cannot open file $ssconf for writing");
print SSCONF $buffer;
close(SSCONF);

system("$qconf -Msconf $ssconf") == 0 or croak("Failed to modify scheduler configuration using file $ssconf");
unlink($ssconf) or croak("Failed to delete file $ssconf");

# Set up default share tree policy
my $stree = system("$qconf -sstree > /dev/null 2>&1");
my $stree_template = "/tmp/stree_template";

if ($stree) {
        open(STREE, '>'.$stree_template) or croak("Cannot open file $stree_template for writing");
        print STREE "id=0\n";
        print STREE "name=default\n";
        print STREE "type=0\n";
        print STREE "shares=1000\n";
        print STREE "childnodes=NONE\n";
        close (STREE);
        system("$qconf -Astree $stree_template") == 0 or croak("Failed to setup Share Tree Policy based on $stree_template");
        unlink($stree_template) or croak("Failed to delete file $stree_template");
}

my $lam_pe = "lam";
my $lam_pe_file = "/tmp/$lam_pe";

my $pvm_pe = "pvm";
my $pvm_pe_file = "/tmp/$pvm_pe";

my $queue = "all";
my $qfile = "$ENV{SGE_ROOT}/$cellname/spool/qmaster/cqueues/$queue.q";

$line = "";
$buffer = "";
my $theline = "";

# Read queue file into memory
open(QFILE, $qfile) or croak("Cannot open file $qfile\n");
while ($line = <QFILE>) {
        $buffer = $buffer.$line;
        if ($line =~ /pe_list/) {
                $theline = $line;
        }
}
close(QFILE, $qfile);

chomp($theline);
my @pes = split(/ +/, $theline);
shift(@pes);

my %pe_exists  = ();
for (@pes) { $pe_exists{$_} = 1 };

# Set up Parallel Environment for LAM/MPI if the package is installed
# FIXME: Right now it checks to see if LAM/MPI is installed on the headnode
if ( is_installed_on_node("$lam_pe") ) {
        # Check to see if we already have "lam" Parallel Environment defined
        `$qconf -sp $lam_pe 2>&1`; # or croak("Cannot run qconf -sp");

        if ($? == 256) {
                # Parallel Environment does not exist, creating...
                opkg_print("Adding LAM/MPI Parallel Environment to SGE\n");
                open(LAM, '>'.$lam_pe_file) or croak("Cannot open file $lam_pe_file for writing");
                print LAM "pe_name           lam\n";
                print LAM "slots             999\n";
                print LAM "user_lists        NONE\n";
                print LAM "xuser_lists       NONE\n";
                print LAM "start_proc_args   $ENV{SGE_ROOT}/pe/lam/startlam.sh -catch_rsh \$pe_hostfile\n";
                print LAM "stop_proc_args    $ENV{SGE_ROOT}/pe/lam/stoplam.sh\n";
                print LAM "allocation_rule   \$round_robin\n";
                print LAM "control_slaves    TRUE\n";
                print LAM "job_is_first_task TRUE\n";
                print LAM "urgency_slots     min\n";
                close(LAM);
                system("$qconf -Ap $lam_pe_file") == 0 or croak("Failed to add LAM/MPI to SGE's Parallel Environment");
                unlink($lam_pe_file);
        } elsif ($? == 0) {
                # LAM/MPI Parallel Environment already exists
        } else {
                croak("Cannot run qconf -sp $lam_pe");
        }

        # Check to see if lam is already referenced in specified queue
        if ($pe_exists{"$lam_pe"}) {
                # LAM/MPI Parallel Environment already set up
        } else {
                opkg_print("Referencing LAM/MPI Parallel Environment in $queue.q\n");
                push(@pes, "$lam_pe");
                my $pe_line = join(" ", @pes);
                $buffer =~ s/pe_list.*\n/pe_list            $pe_line\n/;

                open(QFILE, '>'.$qfile) or croak("Cannot open file $qfile for writing\n");
                print QFILE $buffer;
                close(QFILE);
        }
} else {
        # Check to see if lam is already referenced in specified queue
        if ($pe_exists{"$lam_pe"}) {
                # LAM/MPI Parallel Environment is referenced, need to remove
                opkg_print("Dereferencing LAM/MPI Parallel Environment in $queue.q\n");
                @pes = delete @pes[$lam_pe];
                my $pe_line = join(" ", @pes);
                $buffer =~ s/pe_list.*\n/pe_list            $pe_line\n/;

                open(QFILE, '>'.$qfile) or croak("Cannot open file $qfile for writing\n");
                print QFILE $buffer;
                close(QFILE);
        } else {
                # LAM/MPI Parallel Environment not referenced in queue
        }

        # Check to see if we already have "lam" Parallel Environment defined
        `$qconf -sp $lam_pe 2>&1`; # or croak("Cannot run qconf -sp");

        if ($? == 256) {
                # Parallel Environment does not exist, do nothing
        } elsif ($? == 0) {
                # LAM/MPI Parallel Environment exists
                opkg_print("Deleting LAM/MPI Parallel Environment since LAM/MPI package is not installed\n");
                system("$qconf -dp $lam_pe");
        } else {
                croak("Cannot run qconf -sp $lam_pe");
        }
}

# Set up Parallel Environment for PVM if the package is installed
# FIXME: Right now it checks to see if PVM is installed on the headnode
if ( is_installed_on_node("$pvm_pe") ) {
        # Check to see if we already have "pvm" Parallel Environment defined
        `$qconf -sp $pvm_pe 2>&1`; # or croak("Cannot run qconf -sp");

        if ($? == 256) {
		my $pvm_root = `bash -l -c 'echo \$PVM_ROOT'`;
		chomp($pvm_root);
		$ENV{PVM_ROOT} = $pvm_root;

                # Parallel Environment does not exist, creating...
                opkg_print("Adding PVM Parallel Environment to SGE\n");
                open(PVM, '>'.$pvm_pe_file) or croak("Cannot open file $pvm_pe_file for writing");
                print PVM "pe_name           pvm\n";
                print PVM "slots             999\n";
                print PVM "user_lists        NONE\n";
                print PVM "xuser_lists       NONE\n";
                print PVM "start_proc_args   $ENV{SGE_ROOT}/pe/pvm/startpvm.sh -catch_rsh \$pe_hostfile \$host $ENV{PVM_ROOT}\n";
                print PVM "stop_proc_args    $ENV{SGE_ROOT}/pe/pvm/stoppvm.sh -catch_rsh \$pe_hostfile \$host\n";
                print PVM "allocation_rule   1\n";
                print PVM "control_slaves    TRUE\n";
                print PVM "job_is_first_task FALSE\n";
                print PVM "urgency_slots     min\n";
                close(PVM);
                system("$qconf -Ap $pvm_pe_file") == 0 or croak("Failed to add PVM to SGE's Parallel Environment");
                unlink($pvm_pe_file);
        } elsif ($? == 0) {
                # LAM/MPI Parallel Environment already exists
        } else {
                croak("Cannot run qconf -sp $pvm_pe");
        }

        # Check to see if pvm is already referenced in specified queue
        if ($pe_exists{"$pvm_pe"}) {
                # PVM Parallel Environment already set up
        } else {
                opkg_print("Referencing PVM Parallel Environment in $queue.q\n");
                push(@pes, "$pvm_pe");
                my $pe_line = join(" ", @pes);
                $buffer =~ s/pe_list.*\n/pe_list            $pe_line\n/;

                open(QFILE, '>'.$qfile) or croak("Cannot open file $qfile for writing\n");
                print QFILE $buffer;
                close(QFILE);
        }
} else {
        # Check to see if pvm is already referenced in specified queue
        if ($pe_exists{"$pvm_pe"}) {
                # PVM Parallel Environment is referenced, need to remove
                opkg_print("Dereferencing PVM Parallel Environment in $queue.q\n");
                @pes = delete @pes[$pvm_pe];
                my $pe_line = join(" ", @pes);
                $buffer =~ s/pe_list.*\n/pe_list            $pe_line\n/;

                open(QFILE, '>'.$qfile) or croak("Cannot open file $qfile for writing\n");
                print QFILE $buffer;
                close(QFILE);
        } else {
                # PVM Parallel Environment not referenced in queue
        }

        # Check to see if we already have "pvm" Parallel Environment defined
        `$qconf -sp $pvm_pe 2>&1`; # or croak("Cannot run qconf -sp");

        if ($? == 256) {
                # Parallel Environment does not exist, do nothing
        } elsif ($? == 0) {
                # LAM/MPI Parallel Environment exists
                print "Deleting PVM Parallel Environment since PVM package is not installed\n";
                system("$qconf -dp $pvm_pe");
        } else {
                croak("Cannot run qconf -sp $pvm_pe");
        }
}

# Change ownership of SGE_ROOT so it is owned by the admin user
system("chown $admin_user.$admin_user -R $ENV{SGE_ROOT}");

system("/etc/init.d/sgemaster softstop");
system("/etc/init.d/sgemaster start");

opkg_print("All qmaster-related setup complete.\n");

my $rm_detect_dir = "$ENV{OSCAR_HOME}/lib/OSCAR/OCA/RM_Detect";

# Copy RM_Detect component for SGE to the right location
system("cp -a $ENV{OSCAR_PACKAGE_HOME}/scripts/SGE.pm $rm_detect_dir") == 0 or croak("Failed to copy $ENV{OSCAR_PACKAGE_HOME}/scripts/SGE.pm to $rm_detect_dir");
